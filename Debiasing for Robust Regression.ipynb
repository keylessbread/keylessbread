{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f767e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coefficient of Determination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19eef49",
   "metadata": {},
   "source": [
    "This is a useful coefficient for isolating attributes by detrending data, the r2_score yields a euclidean measurement for the degree of separation of the predicted outcome relative to the true outcome using a hermitian basis.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9377a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_score(ytrue, ypred):\n",
    "  return 1 - sum((ytrue-ypred)**2)/sum((mean(ytrue)-ytrue)**2)\n",
    "\n",
    "def RSS(y_residue):\n",
    "    return 1/2 * np.sum(y_residue**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0983d22",
   "metadata": {},
   "source": [
    "Least Squares for (debiasing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b54c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING DATA\n",
    "n1,m1=Xtrain.shape\n",
    "X_ones1=np.ones((n1,1))\n",
    "X1=np.column_stack((X_ones1,Xtrain))\n",
    "\n",
    "q1,r1 = qr(X1)\n",
    "w1 = solve(r1, q1.T.dot(ytrain))\n",
    "yhat1=X1.dot(w1)\n",
    "\n",
    "#TESTING DATA\n",
    "n2,m2=Xtest.shape\n",
    "X_ones2=np.ones((n2,1))\n",
    "X2=np.column_stack((X_ones2,Xtest))\n",
    "yhat2=X2.dot(w1) #predicted y\n",
    "\n",
    "#R^2 test\n",
    "print('R2 for Least Square for training is ', r2_score(ytrain,yhat1))\n",
    "print('R2 for Least Square is ', r2_score(ytest,yhat2))\n",
    "print('RSS for Least Square is', RSS(ytest-yhat2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cf6a35",
   "metadata": {},
   "source": [
    "Ridge Regression Using Coefficient of Determination (bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c719449",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_span   = linspace(0,2,30)\n",
    "w1_store = zeros((30, 9))\n",
    "error_store = zeros(30)\n",
    "r2_store    = zeros(30)\n",
    "for index in range(len(l_span)):\n",
    "    l         = l_span[index]\n",
    "    sq_Lambda = diag(ones(9)*sqrt(l)) \n",
    "    X1_tilde  = np.vstack([X1, sq_Lambda])\n",
    "    ytrain_tilde   = append(ytrain, zeros(9))\n",
    "    q, r       = linalg.qr(X1_tilde)\n",
    "    w1_tilde    = linalg.solve(r, q.T.dot(ytrain_tilde))\n",
    "    w1_store[index,:] = w1_tilde\n",
    "    w1_hat=np.array([w1_tilde])\n",
    "    yhat1_test = X2.dot(w1_hat.T) \n",
    "    error_store[index] = RSS(ytest-yhat1_test)\n",
    "    r2_store[index]= r2_score(ytest, yhat1_test)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(l_span, error_store)\n",
    "ylabel('RSS')\n",
    "xlabel('$\\lambda$')\n",
    "title('RSS Value for $\\lambda$ Values')\n",
    "grid()\n",
    "print('min of RSS in lambda is', min(error_store))  \n",
    "print('optimal lambda is ', l_span[argmin(error_store)])\n",
    "print('r2 in optimal lambda is', r2_store[argmin(error_store)]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcc76ee",
   "metadata": {},
   "source": [
    "LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66fd032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso(X, y, l1, tol=1e-6):\n",
    "\"\"\"The Lasso Regression model\n",
    "      Pathwise coordinate descent with co-variance updates is applied.\n",
    "\n",
    "      X - NumPy matrix, size (N, d), of standardized numerical predictors, note the first column is ones.\n",
    "      y - NumPy array, length N, of numerical response.\n",
    "      l1 - L1 penalty tuning parameter (positive scalar)\n",
    "      tol - Coordinate Descent convergence tolerance (exited if change < tol)\n",
    "\n",
    "  \"\"\"\n",
    "    m, n      = np.shape(X)\n",
    "    q, r      = linalg.qr(X);\n",
    "    w_s       = linalg.solve(r, q.T.dot(y))\n",
    "    iter   = 0\n",
    "    while True:\n",
    "        w_star = w_s.copy()\n",
    "        for j in range(n):\n",
    "       # norm_X_j = LA.norm(X[:, j])\n",
    "       # selector = [i for i in range(X.shape[1]) if i != j]\n",
    "       # a = X[:, j].dot(y[:, np.newaxis] - X[:, selector].dot(w_s[:, np.newaxis][selector, :]))\n",
    "       # res = np.sign(a) * max(abs(a) - l1, 0)   \n",
    "       # w_s[j] = res/(norm_X_j**2)\n",
    "\n",
    "            a_j     = LA.norm(X[:, j])**2\n",
    "            index   = arange(n)\n",
    "            index_d = delete(index, j)\n",
    "            c_j     = np.dot(X[:,j].T, y-np.dot(X[:,index_d],w_s[index_d]))\n",
    "            update  = c_j/a_j\n",
    "            w_s[j]  = np.sign(update) * max(abs(update) - l1/a_j, 0)   \n",
    "        \n",
    "          iter += 1\n",
    "            if np.all(abs(w_s - w_star) < tol):\n",
    "        #print('Number of iteration is ', iter)\n",
    "        break\n",
    "\n",
    "          return w_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ed7484",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot lasso path\n",
    "l_span   = linspace(0,50,100)\n",
    "w4_store = zeros((100, 9))\n",
    "\n",
    "for index in range(len(l_span)):\n",
    "    l         = l_span[index]\n",
    "    w         = lasso(X1,ytrain, l, tol=1e-6)\n",
    "    w4_store[index,:]=w.T\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for index in range(8):\n",
    "    ax.plot(l_span, w4_store[:,index+1],'-',label= f'{names[index]}')\n",
    "leg = ax.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dfdc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "w=lasso(X1,ytrain,5,tol=1e-06)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a08b4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "\n",
    "!wget https://github.com/yexf308/MAT592/blob/main/homework/HW1/regression_outlier.mat?raw=true -O regression_outlier.mat\n",
    "data = loadmat('regression_outlier.mat')\n",
    "X, Y=data['x_train'], data['y_train']\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot(X,Y,'o',color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa73525e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def fun_1(x):\n",
    "  return sum(abs(Y-x[0]-X*x[1]))\n",
    "\n",
    "m=minimize(fun_1, [0,0])\n",
    "a = m.x\n",
    "\n",
    "def fun_2(x):\n",
    "  return sum((Y-x[0]-X*x[1])**2)\n",
    "\n",
    "n=minimize(fun_2, [0,0])\n",
    "b = n.x\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot(X,Y,'o',color='black')\n",
    "x = np.linspace(0,12,100)\n",
    "plot(x, b[1]*x+b[0], '-b', label='LS regression')\n",
    "plot(x, a[1]*x+a[0], '-r', label='LAD regression')\n",
    "leg = ax.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left');\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
