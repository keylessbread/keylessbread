{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57ec22b9",
   "metadata": {},
   "source": [
    "Gaussian Mixture Model Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1436bb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GMM_fit(X, K, centroids, max_iter=200, threshold =0.0001):\n",
    "  # initialise parameters like weights, Pi, Mu, Sigma of all Gaussians in dataset X\n",
    "  # step 1\n",
    "    Pi, Mu, Sigma, weights = initialize(X,K,centroids)\n",
    "    for j in range(max_iter):\n",
    "        z = predict(X, K, Pi, Mu, Sigma)\n",
    "        Mu_array = array(Mu)\n",
    "    #plot_clusters(X, z, Mu_array)\n",
    "    # step 2 iterate to update the value of P(Zi=c|Xi)\n",
    "    weights = e_step(X, K, Pi, Mu, Sigma)\n",
    "    Pi_old  = Pi;\n",
    "    Mu_old  = Mu;\n",
    "    # step 3 iterate to update the value of Mu, Sigma and Pi as the clusters shift\n",
    "    Pi, Mu, Sigma  = m_step(X, K, weights)\n",
    "\n",
    "    # for stopping \n",
    "    distances = [ norm(Mu[i] - Mu_old[i]) for i in range(K)] \n",
    "    print(sum(distances))\n",
    "    if sum(distances) < threshold:\n",
    "        print('Number of iteration is ', j+1)\n",
    "        break\n",
    "        \n",
    "    z = predict(X, K, Pi, Mu, Sigma)\n",
    "    Mu_array = array(Mu)\n",
    "    plt.scatter(X)\n",
    "    plot_clusters(X, z, Mu_array)\n",
    "\n",
    "    return z, Pi, Mu, Sigma\n",
    "\n",
    "\n",
    "  z,Pi,Mu, si = GMM_fit(X, K, centroids, max_iter=200, threshold =0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb192f8",
   "metadata": {},
   "source": [
    "Log Likelihood Using EM Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede21eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Fitted Model to see likelihood of the given distribution, X\n",
    " def log_likelihood(X,K,Pi_opt,Mu_opt, Sigma_opt):\n",
    "        N = X.shape[0]\n",
    "        likelihood = zeros( (N, K) ) \n",
    "        for i in range(K):\n",
    "            distribution = multivariate_normal(mean=Mu[i],cov=Sigma[i])\n",
    "            # pdf : probability denisty function\n",
    "            likelihood[:,i] = distribution.pdf(X) \n",
    "        log_likelihood = sum(log(likelihood.dot(Pi)))    \n",
    "        print(neg_log_likelihood)\n",
    "        return log_likelihood\n",
    "    \n",
    "      log_likelihood()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963e3919",
   "metadata": {},
   "source": [
    "Bayesian Information Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2121bdae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f52de1d6",
   "metadata": {},
   "source": [
    "Looping for Optimal Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f359a2e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
